{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms as T\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from brian2 import *\n",
    "from brian2hears import *\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import datetime\n",
    "import ipywidgets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import plotly_express as px\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_id = torch.cuda.current_device()\n",
    "use_cuda = True\n",
    "\n",
    "img_height, img_width = (224,224)\n",
    "num_classes = 10\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "n_epochs = 20\n",
    "learn_rate_gamma = 0.7\n",
    "learn_rate_step = 5\n",
    "optimizer_name = 'Adam'\n",
    "\n",
    "conv1_out = 32\n",
    "conv2_out = 32\n",
    "conv3_out = 0\n",
    "conv4_out = 0\n",
    "\n",
    "conv_channels = [conv1_out,conv2_out,conv3_out,conv4_out]\n",
    "active_channels = [i for i in conv_channels if i!=0]\n",
    "num_layers = len(active_channels)\n",
    "last_layer_channels = active_channels[num_layers-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Transform Functions (For Later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAddGaussNoise(object):\n",
    "    def __init__(self, input_size, mean=0.0, std=None, add_noise_probability=1.0):\n",
    "        assert isinstance(input_size, (int, tuple))\n",
    "        assert isinstance(mean, (int, float))\n",
    "        assert isinstance(std, (int, float)) or std is None\n",
    "        assert isinstance(add_noise_probability, (float))\n",
    "\n",
    "\n",
    "        if isinstance(input_size, int):\n",
    "            self.input_size = (input_size, input_size)\n",
    "        else:\n",
    "            assert len(input_size) == 2\n",
    "            self.input_size = input_size\n",
    "\n",
    "        self.mean = mean\n",
    "\n",
    "        if std is not None:\n",
    "            assert std > 0.0\n",
    "            self.std = std\n",
    "        else:\n",
    "            self.std = std\n",
    "\n",
    "        assert add_noise_probability > 0.0 and add_noise_probability <= 1.0\n",
    "        self.add_noise_prob = add_noise_probability\n",
    "\n",
    "\n",
    "    def __call__(self, spectrogram):\n",
    "        if np.random.random() > self.add_noise_prob:\n",
    "            return spectrogram\n",
    "\n",
    "        # set some std value \n",
    "        min_pixel_value = np.min(spectrogram)\n",
    "        if self.std is None:\n",
    "            std_factor = 0.03     # factor number \n",
    "        std = np.abs(min_pixel_value*std_factor)\n",
    "\n",
    "        # generate a white noise spectrogram\n",
    "        gauss_mask = np.random.normal(self.mean, \n",
    "                                    std, \n",
    "                                    size=self.input_size).astype('float32')\n",
    "        \n",
    "        # add white noise to the sound spectrogram\n",
    "        noisy_visual = spectrogram + gauss_mask\n",
    "\n",
    "        return noisy_visual\n",
    "\n",
    "class MyRightShift(object):\n",
    "    def __init__(self, input_size, width_shift_range, shift_probability=1.0):\n",
    "        assert isinstance(input_size, (int, tuple))\n",
    "        assert isinstance(width_shift_range, (int, float))\n",
    "        assert isinstance(shift_probability, (float))\n",
    "\n",
    "        if isinstance(input_size, int):\n",
    "            self.input_size = (input_size, input_size)\n",
    "        else:\n",
    "            assert len(input_size) == 2\n",
    "            self.input_size = input_size\n",
    "\n",
    "        if isinstance(width_shift_range, int):\n",
    "            assert width_shift_range > 0\n",
    "            assert width_shift_range <= self.input_size[1]\n",
    "            self.width_shift_range = width_shift_range\n",
    "        else:\n",
    "            assert width_shift_range > 0.0\n",
    "            assert width_shift_range <= 1.0\n",
    "            self.width_shift_range = int(width_shift_range * self.input_size[1])\n",
    "                        \n",
    "        assert shift_probability > 0.0 and shift_probability <= 1.0\n",
    "        self.shift_prob = shift_probability\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if np.random.random() > self.shift_prob:\n",
    "            return image\n",
    "\n",
    "        # create a new array filled with the min value\n",
    "        shifted_image= np.full(self.input_size, np.min(image), dtype='float32')\n",
    "\n",
    "        # randomly choose a start postion\n",
    "        rand_position = np.random.randint(1, self.width_shift_range)\n",
    "\n",
    "        # shift the image\n",
    "        shifted_image[:,rand_position:] = copy.deepcopy(image[:,:-rand_position])\n",
    "\n",
    "        return shifted_image\n",
    "\n",
    "#applying required transformations on the dataset\n",
    "img_transforms = {\n",
    "    'train':\n",
    "    T.Compose([\n",
    "        MyAddGaussNoise(input_size = img_height,add_noise_probability=0.5),\n",
    "        MyRightShift(input_size = img_height, width_shift_range=0.9, shift_probability=0.5),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5],[0.5])\n",
    "        ]),\n",
    "\n",
    "    'valid':\n",
    "    T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5], [0.5])\n",
    "        ]),\n",
    "\n",
    "    'test':\n",
    "    T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5], [0.5])\n",
    "        ]),\n",
    "     }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset Object (UrbanSound8kDataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSound8kDataset(Dataset):\n",
    "    def __init__(self, featuresdf, transform=None):\n",
    "        assert isinstance(featuresdf, pd.DataFrame)\n",
    "        assert len(featuresdf.columns) == 3\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.featuresdf = featuresdf\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.featuresdf)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        cochleagram, label, fold = self.featuresdf.iloc[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            cochleagram = self.transform(cochleagram)\n",
    "        \n",
    "        cochleagram = cochleagram.type(torch.FloatTensor)\n",
    "\n",
    "        label = torch.as_tensor(np.array(label)).type(torch.LongTensor)\n",
    "\n",
    "        return cochleagram, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scratch PyTorch Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Defining a 2D convolution layer\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=conv1_out,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(conv1_out),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        # torch.Size([batch_size, conv1_out, img_height+1, img_width+1])\n",
    "        \n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=conv1_out,\n",
    "                out_channels=conv2_out,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(conv2_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        if num_layers > 2:\n",
    "            self.conv_layer3 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=conv2_out,\n",
    "                    out_channels=conv3_out,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(conv3_out),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1, padding=1)\n",
    "            )\n",
    "        \n",
    "        if num_layers > 3:\n",
    "            self.conv_layer4 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=conv3_out,\n",
    "                    out_channels=conv4_out,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(conv4_out),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1, padding=1)\n",
    "            )\n",
    "\n",
    "\n",
    "        # torch.Size([batch_size, conv3_out, img_height+3, img_width+3])\n",
    "        #in_features = last_layer_output*(img_height+num_layers)*(img_width+num_layers)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=last_layer_channels*(img_height+num_layers)*(img_width+num_layers), out_features=num_classes)\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        # FIRST CONVOLUTION BLOCK\n",
    "        out = self.conv_layer1(x)\n",
    "\n",
    "        # SECOND CONVOLUTION BLOCK\n",
    "        out = self.conv_layer2(out)\n",
    "\n",
    "        # THIRD CONVOLUTION BLOCK\n",
    "        if num_layers > 2:\n",
    "            out = self.conv_layer3(out)\n",
    "\n",
    "        # FOURTH CONVOLUTION BLOCK\n",
    "        if num_layers > 3:\n",
    "            out = self.conv_layer4(out)\n",
    "\n",
    "        # CLASSIFIER HEAD\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Model Architecture Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model_transfer = Net()\n",
    "\n",
    "    # selecting loss function\n",
    "    criterion_transfer = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_transfer = optim.Adam(model_transfer.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler_transfer = torch.optim.lr_scheduler.StepLR(optimizer_transfer, step_size=learn_rate_step, gamma=learn_rate_gamma)\n",
    "\n",
    "    if use_cuda:\n",
    "        model_transfer = model_transfer.cuda()\n",
    "\n",
    "    return model_transfer, optimizer_transfer, criterion_transfer, scheduler_transfer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loop Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, loaders, model, optimizer, criterion, scheduler, fold_k, data_type, model_name, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    epochs = []\n",
    "    trainingloss = []\n",
    "    validationloss = []\n",
    "    valaccuracy = []\n",
    "    learningrates = []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize the variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        preds = []\n",
    "        targets = []\n",
    "        \n",
    "        ###################\n",
    "        # training the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):     \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()   \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "    \n",
    "        ######################    \n",
    "        # validating the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            pred = output.data.max(1,keepdim=True)[1]\n",
    "            preds.append(pred)\n",
    "            targets.append(target)\n",
    "            # compare predictions\n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "        \n",
    "        train_loss = train_loss/len(train_ds)\n",
    "        valid_loss = valid_loss/len(val_ds)\n",
    "        valid_acc = correct / total\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "\n",
    "        trainingloss.append(train_loss)\n",
    "        validationloss.append(valid_loss)\n",
    "        valaccuracy.append(valid_acc)\n",
    "        epochs.append(epoch)\n",
    "        learningrates.append(current_lr)\n",
    "\n",
    "        # printing training/validation statistics \n",
    "        print('Epoch: {} \\nTraining Loss: {:.6f} \\nValidation Loss: {:.6f} \\nValidation Accuracy: {:.6f} \\nCorrect: {} / {} \\nCurrent LR: {}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            valid_acc,\n",
    "            correct,\n",
    "            total,\n",
    "            current_lr\n",
    "            ))\n",
    "        \n",
    "        ## saving the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "    #GATHER TRAINING RESULTS IN DATAFRAME\n",
    "    validationloss = [i.cpu().tolist() for i in validationloss]\n",
    "    trainingloss = [i.cpu().tolist() for i in trainingloss]\n",
    "    zipped_data = list(zip(epochs, learningrates, trainingloss, validationloss, valaccuracy))\n",
    "    train_report = pd.DataFrame(zipped_data,columns=['Epoch','Learning Rate','Training Loss','Validation Loss','Validation Accuracy'])\n",
    "    train_report['Test Fold'] = fold_k\n",
    "    train_report['Model'] = model_name\n",
    "    train_report['Data Representation'] = data_type\n",
    "    train_report = train_report[['Model','Data Representation', 'Test Fold', 'Epoch', 'Learning Rate', 'Training Loss', 'Validation Loss', 'Validation Accuracy']]\n",
    "    \n",
    "    # return trained model\n",
    "    return model, train_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Script (Load Data From Disk, Train on All 10 Folds, Evaluate on Test Data, Generate Training and Test Metric Reports):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation Name\n",
    "data_type = 'Cochleagram'\n",
    "\n",
    "# Model Name\n",
    "model_name = 'Scratch_PyTorch'\n",
    "\n",
    "# creating data: train, validation, test\n",
    "for fold_k in range(1,num_classes+1):\n",
    "    featuresdf = pd.read_pickle('cgram_224_comp3.pkl')\n",
    "    model_transfer, optimizer_transfer, criterion_transfer, scheduler_transfer = init_model()\n",
    "    train_df = featuresdf[featuresdf['fold'] != fold_k]\n",
    "    val_df = featuresdf[featuresdf['fold'] == fold_k]\n",
    "    test_fold = fold_k\n",
    "\n",
    "    train_ds = UrbanSound8kDataset(train_df, transform=img_transforms['train'])\n",
    "    val_ds = UrbanSound8kDataset(val_df, transform=img_transforms['valid'])\n",
    "\n",
    "    #Creating loaders for the dataset\n",
    "    loaders_transfer={\n",
    "        'train':torch.utils.data.DataLoader(train_ds,batch_size,shuffle=True),\n",
    "        'valid':torch.utils.data.DataLoader(val_ds,batch_size,shuffle=False)\n",
    "    }\n",
    "\n",
    "    del featuresdf, train_df, val_df\n",
    "\n",
    "    if fold_k == 1:\n",
    "        train_report = train_model(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, scheduler_transfer, fold_k, data_type, model_name, model_name + '_' + data_type + '_fold' + str(fold_k) + '.pt')[1]\n",
    "    else:\n",
    "        train_report_temp = train_model(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, scheduler_transfer, fold_k, data_type, model_name, model_name + '_' + data_type + '_fold' + str(fold_k) + '.pt')[1]\n",
    "        train_report = pd.concat([train_report,train_report_temp])\n",
    "    \n",
    "    del model_transfer, optimizer_transfer, criterion_transfer, scheduler_transfer\n",
    "\n",
    "    #RELOAD FINAL CHECKPOINTED MODEL IN FOR VALIDATION RESULTS\n",
    "    model_transfer = init_model()[0]\n",
    "    model_transfer.load_state_dict(torch.load(model_name + '_' + data_type + '_fold' + str(fold_k) + '.pt'))\n",
    "    model_transfer.eval()   \n",
    "\n",
    "    #PERFORM FINAL INFERENCE ON VALIDATION SET\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    class_names = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', 'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loaders_transfer['valid']):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        output = model_transfer(data)\n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        preds.append(prediction.cpu().numpy())\n",
    "        targets.append(target.cpu().numpy())\n",
    "\n",
    "    targets = np.concatenate(targets)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    metrics_report_dict = classification_report(targets, preds, target_names=class_names, output_dict=True)\n",
    "    fold_acc_dict = {'Test Fold' : fold_k , 'Accuracy' : metrics_report_dict['accuracy']}\n",
    "    del metrics_report_dict['accuracy']\n",
    "\n",
    "    if fold_k == 1:\n",
    "        metrics_report = pd.DataFrame(metrics_report_dict).rename_axis('metric').reset_index()\n",
    "        fold_accuracies = pd.DataFrame(fold_acc_dict,index=[0])\n",
    "        metrics_report.insert(0,'Test Fold',fold_k)\n",
    "        metrics_report.insert(0,'Data Representation', data_type)\n",
    "        metrics_report.insert(0,'Model', model_name)\n",
    "    else:\n",
    "        metrics_report_temp = pd.DataFrame(metrics_report_dict).rename_axis('metric').reset_index()\n",
    "        fold_accuracies_temp = pd.DataFrame(fold_acc_dict,index=[0])\n",
    "        metrics_report_temp.insert(0,'Test Fold',fold_k)\n",
    "        metrics_report_temp.insert(0,'Data Representation', data_type)\n",
    "        metrics_report_temp.insert(0,'Model', model_name)\n",
    "        metrics_report = pd.concat([metrics_report, metrics_report_temp])\n",
    "        fold_accuracies = pd.concat([fold_accuracies, fold_accuracies_temp])\n",
    "    \n",
    "    del data, target, output, prediction, targets, preds, metrics_report_dict, fold_acc_dict\n",
    "\n",
    "train_report.to_csv('results/TrainReportbyEpoch_' + model_name + '_' + data_type + '.csv', index=False)\n",
    "metrics_report.to_csv('results/TestMetricsbyClass_' + model_name + '_' + data_type + '.csv', index=False)\n",
    "fold_accuracies.to_csv('results/FoldAccuracies_' + model_name + '_' + data_type + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a52d4c035417b05bd55a248d14e7821f3e49e2f328c6b3af0e0e5c45894566b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
