# Benchmarking Spectral Image Generation Schema and Pre-Trained Convolutional Neural Network Architectures for Audio Classification Tasks
 
Recent advancements in image classification such as Convolutional Neural Networks can be employed to perform audio classification.  While there has been work done on benchmarking different networks and image representations, many techniques remain unexplored.  Three popular pre-trained image networks (EfficentNet-b0, ResNet50, SqueezeNet) and four different image representations of audio (Cochleagram, Approximate Cochleagram, Linear Gammachirp, and Logarithmic Gammachirp) are benchmarked by performance and preprocessing cost using the UrbanSound8K audio dataset, which contains common sounds that contribute to noise pollution in urban areas.  EfficientNet-b0 and ResNet50 achieved comparable performance for each of the four data representations and significantly outperformed SqueezeNet. The Linear Gammachirp and the Cochleagram provided for the highest classification accuracy, with the Linear Gammachirp slightly but not significantly outperforming Cochleagrams.  Findings were surprising because the logarithmic gammachirp filter is a much more computationally complex model of the cochlear inner ear than the other three, and yet it yielded the worst results.  Findings suggest that more complex cochlear models can achieve but do not guarantee better results out of the box, and that optimal tuning of parameters in each cochlear representation may yield improved results.  The limitations of current classification techniques and suggestions for further exploration of different data representations are discussed.

